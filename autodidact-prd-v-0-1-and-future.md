# Autodidact â€“ Product Requirements Document

**Versionâ€¯0.1 (â€œTopicÂ ModeÂ onlyâ€)**Â Â Â <br>**Status:** FinalÂ Â Â <br>**Last updated:** 2025â€‘07â€‘09

> **Audience**Â â€“ This document is meant to be consumed by:
>
> * the *implementationâ€‘agent LLM* that will write code, and
> * any future human contributors.
>
> It MUST contain every design decision made in chat, leaving no hidden context.

---

## TableÂ ofÂ Contents

1. [Vision](#1-vision)
2. ["Neverâ€‘List"](#2-never-list-ğŸš«)Â â€“ permanent nonâ€‘goals
3. [UserÂ StoryÂ (TopicÂ Mode)](#3-user-story-topic-mode)
4. [FunctionalÂ RequirementsÂ (v0.1)](#4-functional-requirements-v01)
5. [Nonâ€‘FunctionalÂ Requirements](#5-non-functional-requirements)
6. [DataÂ Model](#6-data-model)
7. [TechÂ StackÂ (lockedâ€‘in)](#7-tech-stack-locked-in)
8. [SecurityÂ &Â Privacy](#8-security--privacy)
9. [ImplementationÂ NotesÂ forÂ Developers](#9-implementation-notes-for-developers)
10. [Hardâ€‘Won Technical Decisions (summary)](#10-hard-won-technical-decisions-summary)
11. [IncrementalÂ Roadâ€‘map](#11-incremental-road-map)
12. [Future FeatureÂ â€“Â PDFÂ ModeÂ (v0.3)](#12-future-feature--pdf-mode-v03)

---

## 1.Â Vision

Autodidact turns a plainâ€‘language learning goal into a **30â€‘minuteâ€‘perâ€‘session study plan** plus a **conversational AI tutor**.

**VersionÂ 0.1** delivers *TopicÂ Mode* only:

1. **Plan**Â â€“ learner types e.g. â€œLearn Bitcoin & Ethereum internals inÂ 8Â h.â€
2. **Clarify**Â â€“ a short bulletâ€‘question block refines scope.
3. **Syllabus**Â â€“ OpenAI *DeepÂ Research* returns

   * Markdown report
   * knowledge graph (12â€‘35 nodes, â‰ˆ30Â min each)
   * 5â€“7 learning objectives (LOs) per node
4. **Daily Tutor Loop** (GPTâ€‘4oâ€‘mini)

   * greet/recapÂ â†’ teachÂ â†’ quickâ€‘check
   * async grader updates LO mastery & awards XP.

No servers; everything runs on the learnerâ€™s computer. PDF ingestion, RAG and citationâ€‘aware tutoring are postponed toÂ v0.3.

---

## 2.Â Neverâ€‘ListÂ ğŸš«

| Â #Â  | Â Autodidact will **never** â€¦Â                                   | Â ReasonÂ                                        |
| --- | -------------------------------------------------------------- | ---------------------------------------------- |
| Â 1Â  | Â Run as a **multiâ€‘tenant SaaS** (hosted accounts, cloud auth)Â  | Always a personal, local tool.                 |
| Â 2Â  | Â Support **EPUB or other eâ€‘book formats**Â                      | Scope limited to PDF and freeâ€‘form topic text. |
| Â 3Â  | Â Provide **offline/local LLM support**Â                         | Always uses learnerâ€‘supplied OpenAI API key.   |
| Â 4Â  | Â Offer **full custom theming / whiteâ€‘label branding**Â          | UI look is secondary to agent logic.           |
| Â 5Â  | Â Ship a **mobileâ€‘first or native mobile app**Â                  | Desktop browser via Streamlit is sufficient.   |

Any proposal conflicting with this list must be rejected.

---

## 3.Â UserÂ StoryÂ (TopicÂ Mode)

1. **Launch**Â â€“ clone repo â†’ `pip install -r requirements.txt` â†’ `streamlit run app.py`.
2. **APIÂ Key** â€“ firstâ€‘run modal asks for OpenAI key; stored at `~/.autodidact/.env.json` (chmodÂ 600).
3. **Enter Topic** â€“ text box centred: *â€œLearn X (targetÂ hours optional)â€*.
4. **Clarifier** â€“ GPTâ€‘4oâ€‘mini asks â‰¤5 bullets in one message.  Empty/"idk" answers prompt a warning & reâ€‘ask.
5. **DeepÂ Research** â€“ async job; spinner with progress bar.  Polls `/deep_research/{job_id}` everyÂ 3Â s.
6. **Workspace** â€“ twoâ€‘pane layout:

   * **Left**: collapsible Markdown report.
   * **Right**: forceâ€‘directed graph; hover shows summary, LO list, % mastery.
7. **Start Session** â€“ scheduler selects lowestâ€‘mastery unlocked node (tiesÂ â†’ learner picks).
8. **ChatÂ phases** (LangGraph DAG):

   * `greet`Â â€“ (sessionÂ 1) or `recap`Â â€“ (later sessions, 2 recall Qs)
   * `teach`Â â€“ explanation + midâ€‘question
   * `quick_check`Â â€“ final Q, returns JSON LO scores.
9. **Grader** â€“ async pass; updates `lo_mastery`, `node_mastery`; awards XP =Â minutesÂ Ã—Â k.
10. **Graph recolours** â†’ learner done for the day.

---

## 4.Â FunctionalÂ Requirements (vÂ 0.1)

### 4.1Â Landing & Clarifier

* Widgets: `st.text_input` (topic), `st.number_input` (optional hours).
* Clarifier agent prompt:
  *If the topic is ambiguous, ask targeted Qs; else return JSON `{need_clarification:false}`.*
* Skipâ€‘protection loop.

### 4.2Â DeepÂ Research Job

* POST to OpenAI DeepÂ Research (`async=true`).
* Store outputs under `~/.autodidact/projects/<project_id>/`:

  * `report.md`, `graph.json`, raw `deep_research_response.json`.

### 4.3Â Graph & Report Viewer

* Streamlit Component (`reactâ€‘forceâ€‘graph`)

  * Node colour: whiteÂ (#f8f8f8) â†’ greenÂ (#26c176) via linear scale of `masteryÂ 0â€“1`.
  * Hover popâ€‘over: summary, LO list with miniâ€‘bar (â–â–‚â–ƒâ–…â–ˆ).
* `st.markdown(report_md, unsafe_allow_html=True)` inside `st.expander("Report")`.

### 4.4Â Scheduler

* Query:

  ```sql
  SELECT node_id FROM Node
  WHERE prerequisites_met = 1
  ORDER BY node_mastery ASC
  LIMIT 2;
  ```
* If 2 rows: Streamlit `st.radio("Choose topic", â€¦)`.

### 4.5Â TutorÂ Session (LangGraph)

* **Graph definition**

  ```python
  g = StateGraph()
  g.add_node("greet", greet_node)
  g.add_node("recap", recap_node)      # cond
  g.add_node("teach", teach_node)
  g.add_node("quick", quick_node)
  g.add_node("grade", grade_async_node)
  g.add_edge("greet", "recap", cond=lambda s: s["has_prev"])
  g.add_edge("greet", "teach", cond=lambda s: not s["has_prev"])
  g.add_edge("recap", "teach")
  g.add_edge("teach", "quick")
  g.add_edge("quick", "grade")
  compiled = g.compile()
  ```
* Each node function is **pure** (dictÂ â†’ dict) for testability.
* Streaming: `for chunk in compiled.stream(state): st.write_stream(chunk)`.

### 4.6Â Grader

* Prompt uses the same context as tutor (no privileged info).\*  Returns

  ```json
  {"lo_scores":{"lo1":1.0,"lo2":0.7}}
  ```
* Update with EWMA `new = 0.5*old + 0.5*score`.
* XPÂ toast when async job finishes.

### 4.7Â Autosave

* After every turn append to `Transcript`.
* Background task uses `aiosqlite`Â connection pool.

### 4.8Â Voice Input (optional)

* `st_webrtc` recorder; on stopÂ â†’ temp WAVÂ â†’ OpenAI Whisper; preâ€‘fill chat input.

---

## 5.Â Nonâ€‘FunctionalÂ Requirements

| Metric                    | Target             |
| ------------------------- | ------------------ |
| ClarifierÂ + DR initiate   | â‰¤Â 2Â min (95â€‘pct)   |
| Deep Research (DR) step   | â‰¤Â 1 hour           |
| Tutor firstâ€‘token latency | â‰¤Â 3Â s              |
| Memory footprint          | â‰¤Â 1Â GB topic mode  |
| Local install             | â‰¤Â 5Â min, no Docker |
| Cost / 30â€‘min session     | â‰¤Â \$0.05           |

---

## 6.Â DataÂ Model

```mermaid
erDiagram
    Project ||--o{ Node : contains
    Node ||--o{ LO : has
    Project ||--o{ Transcript : has

    Project {
      uuid id PK
      text topic
      text report_path
      timestamp created_at
    }

    Node {
      uuid id PK
      uuid project_id FK
      text label
      text summary
      float mastery default 0
      int page_start 0   -- reserved
      int page_end 0     -- reserved
      bool rag_flag false
    }

    LO {
      uuid id PK
      uuid node_id FK
      text description
      float mastery default 0
    }

    Transcript {
      uuid session_id
      int  turn_idx
      text role
      text content
      timestamp created_at
    }
```

Vector index (future): LanceDB table `Chunk(id, node_id, text, embedding)`.

---

## 7.Â TechÂ Stack (lockedâ€‘in)

| Layer                 | Library / service                   | Notes                             |
| --------------------- | ----------------------------------- | --------------------------------- |
| **UI**                | StreamlitÂ â‰¥Â 1.34                    | Single script, hotâ€‘reload.        |
| **CustomÂ components** | `reactâ€‘forceâ€‘graph`, PDF.js (vÂ 0.3) | via Streamlit Components.         |
| **LLM orchestration** | LangGraph (StateGraph)              | DAG with streaming events.        |
| **LLM provider**      | OpenAI API, model `gpt-4o-mini`     | Clarifier, tutor, grader.         |
| **Deep Research**     | OpenAI Deep Research beta endpoint  | Async job.                        |
| **Background tasks**  | `asyncio.create_task`               | Inâ€‘process; progress dict.        |
| **DB**                | SQLiteÂ + SQLModel                   | File under `~/.autodidact/`.      |
| **Vector DB** (later) | LanceDB                             | Stores embeddings in Arrow files. |
| **Voice**             | `streamlit-webrtc` + Whisper API    | Optional.                         |

---

## 8.Â SecurityÂ &Â Privacy

* No auth; everything local.
* Oneâ€‘time consent banner: *â€œYour prompts & chat are sent to OpenAI for processing.â€*
* API key stored locally with filesystem permissionsÂ 600.

---

## 9.Â Implementation Notes for Developers

1. **File layout**

```bash
autodidact/
â”œâ”€â”€ app.py               # Streamlit entry
â”œâ”€â”€ backend/
    â”œâ”€â”€ jobs.py            # clarifier, deep_research, tutor, grader nodes
    â”œâ”€â”€ db.py              # SQLModel setup
    â”œâ”€â”€ graph.py           # LangGraph compile
â”œâ”€â”€ components/
    â”œâ”€â”€ force_graph/       # React bundle
        â”œâ”€â”€ (pdf_viewer v0.3)
```

2. **State keys**Â â€“ keep all Streamlit state in `st.session_state` (`project_id`, `graph`, `transcript`, `job_progress`).
3. **Error surfacing** â€“ any exception inside a LangGraph node should be caught, written to `Project.error_log`, and shown via `st.error`.
4. **UnitÂ tests** â€“ test every node in isolation with OpenAI stub (return canned text). pytest markers: `@pytest.mark.asyncio`.
5. **Skipâ€‘protection** â€“ regex check for empty / idk answers.
6. **Autosave** â€“ flush transcript every turn to avoid losing data on browser refresh.
7. **Hot reload** â€“ Streamlit reruns script on every input; put job polling inside `st.experimental_rerun()` safe blocks.

---

## 10.Â Hardâ€‘Won Technical Decisions (summary)

1. **Streamlit** chosen over Next.js for zero build & local simplicity.
2. **LangGraph** adopted early to practise agent orchestration and to ease future branching.
3. **Singleâ€‘process asyncio** instead of Celery/Redis â€“ fits singleâ€‘user offline use.
4. **XP formula** simple timeâ€‘based; no social leaderboard.
5. **Graph readâ€‘only inÂ v0.1**; edits added in v0.2.
6. **PDF support deferred toÂ v0.3** but schema fields reserved.
7. **Neverâ€‘list** enshrined (Â§2) to prevent scope creep.

---

## 11.Â Incremental Roadâ€‘map

| Version | Scope | Target effort |
|---------|-------|---------------|
| **0.1** | Topic Mode (this spec) | 2â€“3Â weeks |
| **0.2** | Graph merge/split UI & spacedâ€‘repetition queue | +2Â weeks |
| **0.3** | PDF Mode (see Â§12) | +3Â weeks |

---

## 12.Â Future FeatureÂ â€“Â PDFÂ ModeÂ (v0.3)

### 12.1  Scope recap
* Upload PDFÂ Â Â â†’Â extract TOCÂ Â Â â†’Â Deep Research on TOC.Â 
* Tutor uses chunkâ€‘level RAG; answers cite `(p.Â NN)`.Â 
* Rightâ€‘hand PDF viewer jumps to cited page.

### 12.2  Additional nodes
| Node | Description | Key libs |
|------|-------------|----------|
| `outline_pdf` | Extract `/Outlines`; fallback Gemini Vision firstÂ 20 pages. | PyMuPDF, `google-generativeai` |
| `chunk_embed` | Chunk by TOC leaf, 1Â 000Â tokens / 100Â overlap; embed & save. | PyMuPDF, LanceDB |
| `retrieve_ctx` | Lookup topâ€‘k chunks for node; feed tutor prompt. | LanceDB |

### 12.3  Citation jump
* Tutor/report emit `{{page:42}}` tokens.
* Regex in Streamlit converts to `<a>` with JS `data-page`.
* PDF.js component listens and calls `goToPage(page)`.

### 12.4  Out of scope
* OCR of scanned PDFs, diagrams, multiâ€‘PDF curricula, DRMâ€™d content.

---

**End of PRD â€“ ready for implementation.**
